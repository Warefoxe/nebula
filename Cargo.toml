[package]
name = "nebula"
version = "0.1.0"
edition = "2021"

[dependencies]
clap = { version = "4.5.1", features = ["derive"] }
num_cpus = "1.0"
serde = { version = "1", features = [ "derive" ] }
strfmt = "*"

#llama feature
llama-cpp = { path="backends/llama_cpp/llama-cpp", optional = true }

hf-hub = "0.3.2"
tracing-subscriber = "0.3.18"
tracing-chrome = "0.7.1"

thiserror = "1"
log = "0.4.17"

#whisper feature
hound = { version = "3.5.0", optional = true }
whisper-rs = { git = "https://github.com/tazz4843/whisper-rs", rev = "9861dfdb939d1923beb65adad20acea74afb7a78", optional = true }
cpal = { version = "0.15.1", optional = true }
anyhow = { version = "1.0.70", optional = true }
rubato = { version = "0.15.0", optional = true }

#embeddings feature
candle-core = { git = "https://github.com/huggingface/candle.git", version = "0.5.1", optional = true }
candle-transformers = { git = "https://github.com/huggingface/candle.git", version = "0.5.1", optional = true }
candle-nn = { git = "https://github.com/huggingface/candle.git", version = "0.5.1", optional = true }
tokenizers = { version = "0.19.1", optional = true }

[dev-dependencies]
hf-hub = "0.3.2"

[features]
#default = ["embeddings"]
llama = ["llama-cpp"]
no-metal = ["llama-cpp?/no-metal"]
cuda = ["llama-cpp?/cublas"] #, "candle-core?/cuda", "candle-transformers?/cuda", "candle-nn?/cuda"]
opencl = ["llama-cpp?/clblas"]
openblas = ["llama-cpp?/openblas"]
blis = ["llama-cpp?/blis"]
hip = ["llama-cpp?/hipblas"]
sycl = ["llama-cpp?/sycl"]
whisper = ["whisper-rs", "hound", "cpal", "anyhow", "rubato"]
embeddings = ["candle-core", "candle-transformers", "candle-nn", "tokenizers", "anyhow"]


[[example]]
name = "basic"
required-features = ["llama"]

[[example]]
name = "basic_with_image"
required-features = ["llama"]

[[example]]
name = "whisper_on_wav"
required-features = ["whisper"]

[[example]]
name = "whisper_stream"
required-features = ["whisper"]
